Behavioral Logic Core ComponentsThe system evaluates three primary variables for every question:Result Status: Was the answer CORRECT, INCORRECT, or SKIPPED?Time Taken: Actual seconds spent on the question (timeSpent).Ideal Thresholds: Dynamic limits fetched from Firestore configuration (/static_data/option_sets) based on the specific Exam_Subject.Threshold CalculationsBefore assigning a tag, the system calculates three thresholds:ThresholdCalculation LogicIdeal TimeThe baseline seconds allowed for that subject (e.g., 120s).Careless ThresholdIdeal Time × factorForCarelessAttempt (default 0.25).Good Skip ThresholdIdeal Time × factorForGoodSkip (default 0.20).Tag Assignment MatrixThe logic follows this decision tree to assign one of the six coaching tags:1. If the result is CORRECT:Perfect Attempt: timeSpent ≤ Ideal Time. You answered correctly and managed your time perfectly within the subject's limit.Overtime Correct: timeSpent > Ideal Time. You reached the correct answer, though you spent a bit more time than the ideal limit.2. If the result is INCORRECT:Careless Mistake: timeSpent < Careless Threshold. You answered very quickly but unfortunately missed this one.Wasted Attempt: timeSpent ≥ Careless Threshold. You spent a lot of time here but didn't quite get the right answer.3. If the result is SKIPPED:Good Skip: timeSpent < Good Skip Threshold. You recognized a tough one early and skipped it quickly to save time.Time Wasted: timeSpent ≥ Good Skip Threshold. You spent quite a while on this before skipping.Aggregate AnalyticsIn addition to the per-question tags, the system saves two aggregate maps in the AttemptModel for high-level dashboarding:smartTimeAnalysisCounts: Total count of questions in each of the 6 categories.secondsBreakdownSmartTimeAnalysis: Total seconds spent in each of the 6 categories.This documentation ensures that as you scale, you can tune the carelessFactor or goodSkipFactor in Firestore to adjust how "strict" or "lenient" the coaching feedback becomes

Perfect Attempt
Overtime Correct
Careless Mistake
Wasted Attempt
Good Skip
Time Wasted



StudySmart Project Documentation (Updated Jan 6, 2026)
1. System Overview
StudySmart is a comprehensive NTA-style testing platform that integrates granular time-tracking with "Smart Time Analysis." The system not only scores students but also coaches them on their time management and behavioral patterns during exams.

2. Core Modules
A. Smart Time Analysis Engine (The Brain)
This module categorizes every question attempt into one of six "Coach-Tone" categories based on performance and time spent relative to subject-specific ideal limits.

Dynamic Thresholds:


Ideal Time: Fetched per Exam_Subject (e.g., JEE Main_Physics) from Firestore /static_data/option_sets.


Careless Factor: Percentage (default 0.25) to identify "too fast" incorrect answers.


Good Skip Factor: Percentage (default 20%) to identify "tactical" quick skips.

The 6 Coaching Categories:


Perfect Attempt: "You nailed it! You got the answer right and managed your time perfectly." 


Overtime Correct: "You got it right! Though you spent a bit more time than the ideal limit." 


Careless Mistake: "Slow down a bit! You answered very quickly but unfortunately missed this one." 


Wasted Attempt: "Don't get stuck! You spent a lot of time here but didn't get the right answer." 


Good Skip: "Great tactical move! You recognized a tough one early and skipped it quickly." 


Time Wasted: "Careful with the clock! You spent quite a while on this before skipping." 

B. Test Orchestration Service

TestOrchestrationService handles the critical bridge between local test-taking and Firestore storage.


submitAttempt: Fetches configuration, calculates the 6-tier analysis tags for every question, updates the student_question_tracker, and returns a fully enriched AttemptModel to the UI.


Atomic Batching: Ensures attempts, attempt_items, and student_question_tracker are updated in a single transaction.

C. UI & Analytics Dashboard
The ResultsScreen provides immediate, high-value feedback:

Dual Pie Charts:


Performance Distribution: Traditional Correct/Incorrect/Unattempted split.


Smart Time Analysis: Distribution of the 6 coaching categories, starting at the 12 o'clock position for logical readability.


Interactive Grid: Questions are grouped by their Smart Tags, allowing students to tap a "Qx" bubble to view solutions for specific behavioral mistakes (e.g., viewing all "Careless Mistakes").

3. Data Models
AttemptModel

smartTimeAnalysisCounts: A map storing the totals for the 6 analysis categories (e.g., { "Careless Mistake": 2 }).


responses: A map of ResponseObject where each entry contains a smartTimeAnalysis string.

ResponseObject

smartTimeAnalysis: Stores the full "Friendly Tone" coaching string for that specific question attempt.


timeSpent: Actual time in seconds spent on the question.


status: CORRECT, INCORRECT, or SKIPPED.

4. Firestore Structure Updates
/static_data/option_sets

idealTimePerQuestion: (Map) Key: Exam_Subject, Value: int (seconds).


factorForCarelessAttempt: (Number) e.g., 0.25.


factorForGoodSkip: (Number) e.g., 20.

/attempts/{attemptId}
Now includes the smartTimeAnalysisCounts map for high-level aggregate reporting and the enriched responses map for question-level coaching.

Progress saved. Documentation current as of the latest "Friendly UI" and "Smart Analysis" update.



Here is the comprehensive documentation for the StudySmart project, updated based on the latest codebase provided.

1. File Summaries
Configuration & Entry

pubspec.yaml: Manages project dependencies (Firebase, charts, icons) and asset definitions.

lib/main.dart: Application entry point that initializes Firebase and handles root navigation (Auth vs. Home) based on login state.

Authentication & Onboarding

lib/features/auth/screens/auth_page.dart: A toggle wrapper that switches between the Login and Register screens.

lib/features/auth/screens/auth_wrapper.dart: Determines if a logged-in user should go to the Home screen or complete their Onboarding profile first.

lib/features/auth/screens/login_screen.dart: UI for users to sign in via Email/Password or Google.

lib/features/auth/screens/register_screen.dart: UI for new users to create an account with Email and Password.

lib/features/auth/screens/onboarding_screen.dart: Collects role-specific data (Student vs. Teacher) and profile details (e.g., Target Exam, Class) after sign-up.

lib/services/auth_service.dart: Handles Firebase Authentication logic including Sign In, Sign Up, and Google Auth.

lib/services/onboarding_service.dart: Manages creating user profiles in Firestore, including transactional generation of unique Student IDs.

Home & Dashboard

lib/features/home/screens/home_screen.dart: The main shell of the app, handling the Drawer and Tab navigation for both Students and Teachers.

lib/models/user_model.dart: Data model representing the user's profile, role (student/teacher), and aggregate statistics.

Student Features (Assignments & Custom Tests)

lib/features/student/widgets/student_assignments_list.dart: Displays lists of assigned tests/homework for the student, filtering by "Strict" or "Practice" mode.

lib/features/test_creation/screens/custom_test_history_screen.dart: Lists student-generated custom tests and provides an entry point to create new ones.

lib/features/test_creation/screens/syllabus_screen.dart: Allows students to select specific chapters/topics to generate a custom practice test.

lib/widgets/test_configuration_bottom_sheet.dart: Configuration UI to set the question count and duration for a new custom test.

lib/services/custom_test_service.dart: Handles saving and retrieving student-generated test blueprints in Firestore.

lib/services/test_service.dart: Logic to generate a randomized test blueprint based on selected syllabus topics.

lib/models/custom_test_model.dart: Data model for a test created by a student.

Teacher Features (Curation & Management)

lib/features/teacher/screens/teacher_curation_screen.dart: Step 1 of curation; allows teachers to look up student stats and define the target audience.

lib/features/teacher/screens/teacher_filter_screen.dart: Step 2 of curation; provides advanced filters (Syllabus, Smart Filters) to select questions and assign them.

lib/features/teacher/screens/curation_management_screen.dart: Allows teachers to manage active assignments (Reorder/Randomize questions) and view specific performance.

lib/features/teacher/screens/teacher_history_screen.dart: Displays a historical list of all assignments created by the teacher.

lib/services/teacher_service.dart: Logic for fetching student stats, searching/filtering questions, and creating assignment records.

lib/widgets/student_lookup_sheet.dart: A UI tool for teachers to search for a student by their unique ID to view their analytics.

Test Taking Engine (The Player)

lib/features/test_taking/screens/enter_code_screen.dart: Allows users to access a specific test using a shared alphanumeric code.

lib/features/test_taking/screens/test_preview_screen.dart: Shows test details (Syllabus, Duration, Question Count) before the attempt starts.

lib/features/test_taking/screens/test_screen.dart: The core exam interface handling the timer, question navigation, answer recording, and submission.

lib/services/test_orchestration_service.dart: Central service managing the lifecycle of a test attempt (Fetch, Submit, Score).

lib/widgets/question_input_widget.dart: Renders the appropriate input UI (Radio buttons, Checkboxes, Text Field) based on QuestionType.

lib/widgets/question_palette.dart: A grid widget showing the status (Answered, Review, Skipped) of all questions in the test.

lib/widgets/expandable_image.dart: A utility widget that allows question/solution images to be zoomed/expanded on tap.

lib/models/question_model.dart: Defines the structure of a Question (text, image, type, correct answer).

lib/models/test_model.dart: Represents the blueprint of a generated test (config, list of question IDs).

lib/models/nta_test_models.dart: Helper models (like AnswerState) for tracking UI state during a test.

lib/models/test_enums.dart: Defines enumerations like TestMode (Practice vs Test).

Analytics & History

lib/features/analytics/screens/analysis_screen.dart: Main analytics hub displaying performance tabs ("Assignments" vs "Tests").

lib/features/analytics/screens/results_screen.dart: Detailed post-test report showing score, accuracy, charts, and question-wise breakdown.

lib/features/analytics/screens/test_history_screen.dart: Lists all past attempts for a user.

lib/features/analytics/widgets/attempt_list_widget.dart: Fetches and lists AttemptModel data from Firestore.

lib/features/analytics/widgets/attempt_display_card.dart: Reusable card component to display a summary of a single attempt.

lib/widgets/solution_detail_sheet.dart: A bottom sheet showing the detailed solution and self-analysis options for a specific question.

lib/models/attempt_model.dart: Represents the summary of a completed test attempt (Score, Time, Aggregates).

lib/models/attempt_item_model.dart: Represents the granular result of a single question within an attempt.

lib/models/test_result.dart: A transient model used to pass full data (Questions + User Answers) to the Results screen.

2. Module Documentation
A. Authentication & User Profile
Flow: User signs up/in -> AuthWrapper checks onboardingCompleted -> Redirects to OnboardingScreen (if false) or HomeScreen (if true).

Screens: LoginScreen, RegisterScreen, OnboardingScreen.

Firestore Data:

Collection: users

Model: UserModel

Key Fields: role ('student'/'teacher'), studentId (unique int), targetExam, teachingSubjects.

B. Teacher Curation (Assignment Creation)
Flow:

Teacher selects audience (e.g., "Particular Student") in TeacherCurationScreen.

Teacher filters questions (Subject -> Chapter -> Topic or Smart Filters like "Incorrect Questions") in TeacherFilterScreen.

Teacher selects questions and clicks "Assign".

Teacher manages active assignments (Reorder/Randomize) in CurationManagementScreen.

Firestore Data:

Collection: questions (Read-only pool).

Collection: questions_curation (Write). Holds the assignment blueprint.

Fields: studentUid, questionIds (Array), assignmentCode, status, onlySingleAttempt.

Collection: student_question_tracker (Update).

Fields: assigned_history (Array of IDs), buckets (Map of status lists).

C. Student Dashboard & Assignments
Flow: Student logs in -> Sees "Assignments" (Practice) and "Tests" (Strict) tabs -> Taps a card to start.

Screens: HomeScreen, StudentAssignmentsList.

Firestore Data:

Collection: questions_curation. Query: where('studentUid', '==', currentUser.uid).

D. Test Taking Engine (The Player)
Flow:

Initiation: Via StudentAssignmentsList (Assigned) or EnterCodeScreen (Public).

Preview: TestPreviewScreen shows metadata.

Attempt: TestScreen handles the loop (Timer -> Input -> Navigation).

Submission: TestOrchestrationService calculates score and saves data.

Data Models:

Question: Mapped from Firestore. Handles types: Single Correct, Numerical, Matrix.

AnswerState: Tracks local UI state (selected option, marked for review).

Firestore Data:

Collection: attempts (The session summary).

Collection: attempt_items (Granular logs for every question).

E. Analytics & Results
Flow:

Immediate: After submission, user is redirected to ResultsScreen.

Historical: Accessed via AnalysisScreen or TestHistoryScreen.

Screens: ResultsScreen (Charts, Stats), SolutionDetailSheet (Review).

Firestore Data:

Collection: attempts.

Fields: score, accuracy, timeTakenSeconds, responses (Map of question results).

F. Custom Test Creation (Student)
Flow: CustomTestHistoryScreen -> SyllabusScreen (Select Topics) -> TestConfiguration (Set Time/Count) -> Generate.

Logic: TestService.generateTest randomly selects questions from the syllabus pool matching an 80/20 split (SCQ/Numerical).

Firestore Data:

Collection: tests (Blueprint of the generated test).